\documentclass{article}
\usepackage{noweb}
\usepackage{amsmath}
\usepackage{graphicx}
%\usepackage{times}
\addtolength{\textwidth}{1in}
\addtolength{\oddsidemargin}{-.5in}
\setlength{\evensidemargin}{\oddsidemargin}

\newcommand{\myfig}[1]{\includegraphics[width=\textwidth]{figure/#1.pdf}}
\newcommand{\code}[1]{\texttt{#1}}

\title{The \emph{coxme} function in S}
\author{Terry Therneau \\ Mayo Clinic}

\begin{document}
\maketitle
\tableofcontents
\section{Introduction}
 The [[coxme]] function for mixed effects analyses based on a Cox
proportional hazards model is one of the later additions to my 
survival functions in S
\footnote{S is a statistical language with R and S-Plus being implementations
 of that language.  I use R daily, but still refer to my code as S}.
It is easily the most complex bit of code in this ecosystem from all points
of view: mathematical, algorithmic, and R code wise.
As such, it seems like a natural candidate for documentation and 
maintainance using the literal programming model.  
\begin{quotation}
Let us change or traditional attitude to the construction of programs.
Instead of imagining that our main task is to instruct a \emph{computer}
what to do, let us concentrate rather on explaining to \emph{humans}
what we want the computer to do.  (Donald E. Knuth, 1984).
\end{quotation}

This document is my first foray into said domain.  
Time will tell if it is successful in creating both more reliable and
better understood code.

Note that almost all of the code uses a \emph{.Rnw} suffix, taking
advantage of the very capable emacs modes that are part of the ESS pacakge.
However, it is not processed by the [[Sweave]] or [[knitR]]
packages, both of which are designed for reports containing 
\emph{exectuted} S code.   
In contrast this document makes use of the [[noweb]] package to document (weave)
and generate the R source code (tangle) from a single file.
The [[noweb]] weave command is considerably simpler than that for [[knitr]]
since it does not have to evaluate code, while its tangle function is
more complex.

\section{Main program}
The [[coxme]] code starts with a fairly standard argument list.
<<coxme>>=
coxme <- function(formula,  data, 
	weights, subset, na.action, init, 
	control, ties= c("efron", "breslow"),
	varlist, vfixed, vinit,
	x=FALSE, y=TRUE, 
        refine.n=0, random, fixed, variance,  ...) {

    #time0 <- proc.time()    #debugging line
    ties <- match.arg(ties)
    Call <- match.call()

    <<process-standard-arguments>>
    <<decompose-formula>>
    <<build-control-structures>>
    <<call-computation-routine>>
    <<finish-up>>
}
@

The arguments to the function are described below,
omitting those that are identical to the [[coxph]] function.
\begin{description}
\item[formula] The formula desribing the fixed and random effects.  This
will be discussed in detail below.
\item[varlist] An optional list, with one element per random term, that
describes the variance structure of the random effects.  It need not
be a list if there is only one random term.
\item[vfixed] An optional list (or vector) of fixed values for 
selected variance
components.  
\item[vinit] Initial value(s) for the variance components in the iteration.
\item[refine.n] The number of Monte Carlo iterations to be done at the final
iteration, to refine the Laplace approximation of the likelihood.
\item[random, fixed, variance] These are included for backwards compatability 
with the first verion of coxme.  They may be removed at some
point in the future.
\end{description}

The [[sparse]] option has been moved to the coxme.control function.
Cox model variance matrices are never sparse, but we have found that
in one very particular instance we can ignore many off-diagonal
elements.  This combined with the naturally sparse structure of
the penalty matrix can lead to substantial reductions in
computational time.  
The ignorable elements arise for a random intercept term.  In this case
the diagonal elements of the usual Cox model variance matrix
are $O(p_i)$ and the off diagonals are $O(p_i p_j)$, where $p_i$ is
the fraction of subjects in group $i$.
If both $p_i$ and $p_j$ are sufficiently small the corresponding
off-diagonal may be effectively ignored.
For a particular family study that motivated the code there were
over twenty thousand subjects, with a random intercept per subject, and
the computation was not feasable without this addition.
Based on fairly limited experience, the lower level for the
approximation is set at $p= 1/50$.  
The default values for the [[sparse]] option state that the approximation
should only be used if there are $>50$ levels for the grouping factor, and
only for those groups representing .02 or less of the total.
If there are multiple random effects only one is allowed a sparse
representation, nor are random slopes ever represented in this way.
Further reseach may reveal wider circumstances in which the approximation
is workable, but for now only the one known case is allowed.



